{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "import spacy\n",
    "nlp=spacy.load('es_core_news_sm')\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuestas = pd.read_csv('tbl_respuestas.csv', sep=',', encoding='utf_8')\n",
    "respuestas.drop(\"Modalidad\", axis=1, inplace=True)\n",
    "#respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = input(\"texto: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>como es la carrera de agronomia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           oracion\n",
       "0  como es la carrera de agronomia"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_textos = pd.DataFrame(columns = ['oracion'])\n",
    "df_textos.loc[0] = [aa] \n",
    "df_textos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcesar_carrera(Corpus, POS=False, Lema=True, Stem=True):\n",
    "    \n",
    "    \n",
    "    # Generar una lista de documentos de spacy para tratar el POS Tagging y la Lematización\n",
    "    docs=[]\n",
    "    for oracion in Corpus:\n",
    "        docs.append(nlp(oracion.lower())) #La lematización funciona mejor en minúsculas\n",
    "    \n",
    "    # Crear una lista de oraciones, donde cada elemento es una lista de palabras.\n",
    "    # Cada palabra está definida por una tupla (Texto, POSTag, Lema)\n",
    "    # Se omiten los tokens que son identificados como signos de puntuación\n",
    "    oraciones=[]\n",
    "    for doc in docs:\n",
    "        oracion=[]\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'PUNCT':\n",
    "                oracion.append((token.text, token.pos_, token.lemma_))\n",
    "        oraciones.append(oracion)\n",
    "    \n",
    "    fc = open('stopwords.txt', 'r', encoding='utf8')\n",
    "    stopwords = fc.read().split('\\n')\n",
    "    fc.close()\n",
    "    oraciones = [[palabra for palabra in oracion if palabra[2] not in stopwords] for oracion in oraciones]\n",
    "    \n",
    "    # Stemming\n",
    "    if Stem==True:\n",
    "        oraciones_aux=[]\n",
    "        for oracion in oraciones:\n",
    "            oracion_aux=[]\n",
    "            for palabra in oracion:\n",
    "                p_texto, p_pos, p_lema = palabra\n",
    "                # Si Lema es True, se Stemmatiza el lema; si no, se Stemmatiza la palabra original\n",
    "                if Lema==True:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_lema)))\n",
    "                else:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_texto)))\n",
    "            oraciones_aux.append(oracion_aux)\n",
    "        \n",
    "        oraciones = oraciones_aux\n",
    "    \n",
    "    Corpus_Procesado = [] #Variable de salida\n",
    "    \n",
    "    for doc in oraciones:\n",
    "        oracion = ''\n",
    "        for palabra in doc:\n",
    "            if Stem == True:\n",
    "                # Devolver cadena de Stemming\n",
    "                oracion = oracion + palabra[3]\n",
    "            else:\n",
    "                if Lema == True:\n",
    "                    # Devolver cadena de Lemas\n",
    "                    oracion = oracion + palabra[2]\n",
    "                else:\n",
    "                    # Devolver cadena de palabras originales\n",
    "                    oracion = oracion + palabra[0]\n",
    "            \n",
    "            if POS == True:\n",
    "                #Concatenar POS a cada palabra\n",
    "                oracion = oracion + '_' + palabra[1].lower()\n",
    "            \n",
    "            oracion = oracion + ' '\n",
    "        \n",
    "        Corpus_Procesado.append(oracion)\n",
    "        \n",
    "    return Corpus_Procesado\n",
    "\n",
    "def Corregir_Documentos_carrera(df_textos, columnas, POS=False, Lema=True, Stem=True):\n",
    "\n",
    "    for col in columnas:\n",
    "        df_textos[col] = PreProcesar_carrera(list(df_textos[col]), POS, Lema, Stem)\n",
    "    \n",
    "    # Sanear el DataFrame eliminando los duplicados y reindexándolo\n",
    "    df_textos = df_textos.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return df_textos\n",
    "\n",
    "#####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agronomi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     oracion\n",
       "0  agronomi "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vari_df_textos_carr= df_textos.copy()\n",
    "carrera_corr = Corregir_Documentos_carrera(vari_df_textos_carr,['oracion'],False,True,True)\n",
    "carrera_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "def PreProcesar_w5(Corpus, POS=False, Lema=True, Stem=True):\n",
    "    \n",
    "    \n",
    "    # Generar una lista de documentos de spacy para tratar el POS Tagging y la Lematización\n",
    "    docs=[]\n",
    "    for oracion in Corpus:\n",
    "        docs.append(nlp(oracion.lower())) #La lematización funciona mejor en minúsculas\n",
    "    \n",
    "    # Crear una lista de oraciones, donde cada elemento es una lista de palabras.\n",
    "    # Cada palabra está definida por una tupla (Texto, POSTag, Lema)\n",
    "    # Se omiten los tokens que son identificados como signos de puntuación\n",
    "    oraciones=[]\n",
    "    for doc in docs:\n",
    "        oracion=[]\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'PUNCT':\n",
    "                oracion.append((token.text, token.pos_, token.lemma_))\n",
    "        oraciones.append(oracion)\n",
    "    \n",
    "    ww = open('stopwords_sin_w5.txt', 'r', encoding='utf8')\n",
    "    stopwords = ww.read().split('\\n')\n",
    "    #stopwords=[x.lower() for x in stopwords]\n",
    "    ww.close()\n",
    "    oraciones = [[palabra for palabra in oracion if palabra[2] not in stopwords] for oracion in oraciones]\n",
    "    \n",
    "    # Stemming\n",
    "    if Stem==True:\n",
    "        oraciones_aux=[]\n",
    "        for oracion in oraciones:\n",
    "            oracion_aux=[]\n",
    "            for palabra in oracion:\n",
    "                p_texto, p_pos, p_lema = palabra\n",
    "                # Si Lema es True, se Stemmatiza el lema; si no, se Stemmatiza la palabra original\n",
    "                if Lema==True:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_lema)))\n",
    "                else:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_texto)))\n",
    "            oraciones_aux.append(oracion_aux)\n",
    "        \n",
    "        oraciones = oraciones_aux\n",
    "    \n",
    "    Corpus_Procesado = [] #Variable de salida\n",
    "    \n",
    "    for doc in oraciones:\n",
    "        oracion = ''\n",
    "        for palabra in doc:\n",
    "            if Stem == True:\n",
    "                # Devolver cadena de Stemming\n",
    "                oracion = oracion + palabra[3]\n",
    "            else:\n",
    "                if Lema == True:\n",
    "                    # Devolver cadena de Lemas\n",
    "                    oracion = oracion + palabra[2]\n",
    "                else:\n",
    "                    # Devolver cadena de palabras originales\n",
    "                    oracion = oracion + palabra[0]\n",
    "            \n",
    "            if POS == True:\n",
    "                #Concatenar POS a cada palabra\n",
    "                oracion = oracion + '_' + palabra[1].lower()\n",
    "            \n",
    "            oracion = oracion + ' '\n",
    "        \n",
    "        Corpus_Procesado.append(oracion)\n",
    "        \n",
    "    return Corpus_Procesado\n",
    "\n",
    "def Corregir_Documentos_w5(df_textos, columnas, POS=False, Lema=True, Stem=True):\n",
    "\n",
    "    for col in columnas:\n",
    "        df_textos[col] = PreProcesar_w5(list(df_textos[col]), POS, Lema, Stem)\n",
    "    \n",
    "    # Sanear el DataFrame eliminando los duplicados y reindexándolo\n",
    "    df_textos = df_textos.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return df_textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  oracion\n",
       "0    com "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vari_df_textos_w5= df_textos.copy()\n",
    "w5_corr = Corregir_Documentos_w5(vari_df_textos_w5,['oracion'],False,True,True)\n",
    "w5_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "def PreProcesar_intents(Corpus, POS=False, Lema=True, Stem=True):\n",
    "    \n",
    "    \n",
    "    # Generar una lista de documentos de spacy para tratar el POS Tagging y la Lematización\n",
    "    docs=[]\n",
    "    for oracion in Corpus:\n",
    "        docs.append(nlp(oracion.lower())) #La lematización funciona mejor en minúsculas\n",
    "    \n",
    "    # Crear una lista de oraciones, donde cada elemento es una lista de palabras.\n",
    "    # Cada palabra está definida por una tupla (Texto, POSTag, Lema)\n",
    "    # Se omiten los tokens que son identificados como signos de puntuación\n",
    "    oraciones=[]\n",
    "    for doc in docs:\n",
    "        oracion=[]\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'PUNCT':\n",
    "                oracion.append((token.text, token.pos_, token.lemma_))\n",
    "        oraciones.append(oracion)\n",
    "    \n",
    "    ww = open('stopwords_intents.txt', 'r', encoding='utf8')\n",
    "    stopwords = ww.read().split('\\n')\n",
    "    stopwords=[x.lower() for x in stopwords]\n",
    "    ww.close()\n",
    "    oraciones = [[palabra for palabra in oracion if palabra[2] not in stopwords] for oracion in oraciones]\n",
    "    \n",
    "    # Stemming\n",
    "    if Stem==True:\n",
    "        oraciones_aux=[]\n",
    "        for oracion in oraciones:\n",
    "            oracion_aux=[]\n",
    "            for palabra in oracion:\n",
    "                p_texto, p_pos, p_lema = palabra\n",
    "                # Si Lema es True, se Stemmatiza el lema; si no, se Stemmatiza la palabra original\n",
    "                if Lema==True:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_lema)))\n",
    "                else:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_texto)))\n",
    "            oraciones_aux.append(oracion_aux)\n",
    "        \n",
    "        oraciones = oraciones_aux\n",
    "    \n",
    "    Corpus_Procesado = [] #Variable de salida\n",
    "    \n",
    "    for doc in oraciones:\n",
    "        oracion = ''\n",
    "        for palabra in doc:\n",
    "            if Stem == True:\n",
    "                # Devolver cadena de Stemming\n",
    "                oracion = oracion + palabra[3]\n",
    "            else:\n",
    "                if Lema == True:\n",
    "                    # Devolver cadena de Lemas\n",
    "                    oracion = oracion + palabra[2]\n",
    "                else:\n",
    "                    # Devolver cadena de palabras originales\n",
    "                    oracion = oracion + palabra[0]\n",
    "            \n",
    "            if POS == True:\n",
    "                #Concatenar POS a cada palabra\n",
    "                oracion = oracion + '_' + palabra[1].lower()\n",
    "            \n",
    "            oracion = oracion + ' '\n",
    "        \n",
    "        Corpus_Procesado.append(oracion)\n",
    "        \n",
    "    return Corpus_Procesado\n",
    "\n",
    "def Corregir_Documentos_intents(df_textos, columnas, POS=False, Lema=True, Stem=True):\n",
    "\n",
    "    for col in columnas:\n",
    "        df_textos[col] = PreProcesar_intents(list(df_textos[col]), POS, Lema, Stem)\n",
    "    \n",
    "    # Sanear el DataFrame eliminando los duplicados y reindexándolo\n",
    "    df_textos = df_textos.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return df_textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com carrer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oracion\n",
       "0  com carrer "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vari_df_textos_inte= df_textos.copy()\n",
    "inte_corr = Corregir_Documentos_intents(vari_df_textos_inte,['oracion'],False,True,True)\n",
    "inte_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com carrer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oracion\n",
       "0  com carrer "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vari_df_textos_sub_inte= df_textos.copy()\n",
    "sub_inte_corr = Corregir_Documentos_intents(vari_df_textos_sub_inte,['oracion'],False,True,True)\n",
    "sub_inte_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agronomi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     oracion\n",
       "0  agronomi "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carrera_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador_carreras = pickle.load(open(\"vectorizador_carreras.pkl\",\"rb\"))\n",
    "df_matriz_carreras = pickle.load(open(\"df_matriz_carreras.pkl\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizador_carreras.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_carreras=vectorizador_carreras.transform([carrera_corr['oracion'][0][:-1]])\n",
    "#y=vectorizador.transform(['artificial cienci'])\n",
    "array_carreras.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_carreras = pickle.load(open(\"modelo_carreras.sav\",\"rb\"))\n",
    "#carrera = (clf_carrera.predict_proba(lola))[:,1]\n",
    "carrera =sorted(list(modelo_carreras.predict_proba(array_carreras)[0]))[-1]\n",
    "carrera2 = modelo_carreras.predict(array_carreras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999951153912673"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carrera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Agro'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carrera2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  oracion\n",
       "0    com "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "w5_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador_w5 = pickle.load(open(\"vectorizador_w5.pkl\",\"rb\"))\n",
    "#vectorizador_w5.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_w5=vectorizador_w5.transform([w5_corr['oracion'][0][:-1]])\n",
    "#y=vectorizador.transform(['artificial cienci'])\n",
    "array_w5.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_w5 = pickle.load(open(\"modelo_w5.sav\",\"rb\"))\n",
    "#carrera = (clf_carrera.predict_proba(lola))[:,1]\n",
    "w5 = sorted(list(modelo_w5.predict_proba(array_w5)[0]))[-1]\n",
    "w5_2 = modelo_w5.predict(array_w5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999994085903269"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['como'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w5_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com carrer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oracion\n",
       "0  com carrer "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################\n",
    "inte_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador_intents = pickle.load(open(\"vectorizador_intents.pkl\",\"rb\"))\n",
    "#vectorizador_intents.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_intents=vectorizador_intents.transform([inte_corr['oracion'][0][:-1]])\n",
    "#y=vectorizador.transform(['artificial cienci'])\n",
    "array_intents.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_intents = pickle.load(open(\"modelo_intents.sav\",\"rb\"))\n",
    "#carrera = (clf_carrera.predict_proba(lola))[:,1]\n",
    "intents = sorted(list(modelo_intents.predict_proba(array_intents)[0]))[-1]\n",
    "intents_2 = modelo_intents.predict(array_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999984768"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['generalidades'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com carrer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oracion\n",
       "0  com carrer "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################\n",
    "sub_inte_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador_sub_intents = pickle.load(open(\"vectorizador_sub_intents.pkl\",\"rb\"))\n",
    "#vectorizador_sub_intents.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_sub_intents=vectorizador_sub_intents.transform([sub_inte_corr['oracion'][0][:-1]])\n",
    "#y=vectorizador.transform(['artificial cienci'])\n",
    "array_sub_intents.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_sub_intents = pickle.load(open(\"modelo_sub_intents.sav\",\"rb\"))\n",
    "#carrera = (clf_carrera.predict_proba(lola))[:,1]\n",
    "sub_intents = sorted(list(modelo_sub_intents.predict_proba(array_sub_intents)[0]))[-1]\n",
    "sub_intents_2 = modelo_sub_intents.predict(array_sub_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999189254071"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['todas'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_intents_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generalidades', 'todas', 'Agro', 'como']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intencion</th>\n",
       "      <th>SubIntencion</th>\n",
       "      <th>Carrera</th>\n",
       "      <th>w5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>Agro</td>\n",
       "      <td>como</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Intencion SubIntencion Carrera    w5\n",
       "0  generalidades        todas    Agro  como"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listita = [intents_2[0], sub_intents_2[0], carrera2[0], w5_2[0]]\n",
    "df_textos_listo = pd.DataFrame(columns = ['Intencion',\"SubIntencion\",\"Carrera\",\"w5\"])\n",
    "df_textos_listo.loc[0] = listita\n",
    "df_textos_listo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = (df_textos_listo[\"Carrera\"]==respuestas[\"Carrera\"])\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRespuesta</th>\n",
       "      <th>Intencion</th>\n",
       "      <th>SubIntencion</th>\n",
       "      <th>Carrera</th>\n",
       "      <th>w5</th>\n",
       "      <th>Respuesta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>IA</td>\n",
       "      <td>todas</td>\n",
       "      <td>A partir de la captación y procesamiento de da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>MM</td>\n",
       "      <td>todas</td>\n",
       "      <td>Como Diseñador de Multimedios, serás un profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>DG</td>\n",
       "      <td>todas</td>\n",
       "      <td>El diseño gráfico es una disciplina indispensa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>Pub</td>\n",
       "      <td>todas</td>\n",
       "      <td>En la actualidad y desde siempre, la publicida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>RRPP</td>\n",
       "      <td>todas</td>\n",
       "      <td>Las Relaciones Públicas constituyen un conjunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>tramites</td>\n",
       "      <td>todas</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>\\nLa preinscripción puede hacerse a través de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>tramites</td>\n",
       "      <td>preinscripcion</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>\\nLa preinscripción puede hacerse a través de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>tramites</td>\n",
       "      <td>cies</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>La preinscripción puede hacerse a través de nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>tramites</td>\n",
       "      <td>requisitos</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>La preinscripción puede hacerse a través de nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>tramites</td>\n",
       "      <td>equivalencias</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>\\nLos trámites de Equivalencias se pueden inic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDRespuesta      Intencion    SubIntencion Carrera     w5  \\\n",
       "0             1  generalidades           todas      IA  todas   \n",
       "1             2  generalidades           todas      MM  todas   \n",
       "2             3  generalidades           todas      DG  todas   \n",
       "3             4  generalidades           todas     Pub  todas   \n",
       "4             5  generalidades           todas    RRPP  todas   \n",
       "..          ...            ...             ...     ...    ...   \n",
       "81           82       tramites           todas   todas  donde   \n",
       "82           83       tramites  preinscripcion   todas  donde   \n",
       "83           84       tramites            cies   todas  donde   \n",
       "84           85       tramites      requisitos   todas  donde   \n",
       "85           86       tramites   equivalencias   todas  donde   \n",
       "\n",
       "                                            Respuesta  \n",
       "0   A partir de la captación y procesamiento de da...  \n",
       "1   Como Diseñador de Multimedios, serás un profes...  \n",
       "2   El diseño gráfico es una disciplina indispensa...  \n",
       "3   En la actualidad y desde siempre, la publicida...  \n",
       "4   Las Relaciones Públicas constituyen un conjunt...  \n",
       "..                                                ...  \n",
       "81  \\nLa preinscripción puede hacerse a través de ...  \n",
       "82  \\nLa preinscripción puede hacerse a través de ...  \n",
       "83  La preinscripción puede hacerse a través de nu...  \n",
       "84  La preinscripción puede hacerse a través de nu...  \n",
       "85  \\nLos trámites de Equivalencias se pueden inic...  \n",
       "\n",
       "[86 rows x 6 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d333c3e79956f6cfdda154d497169890c9e1b3b648807dd58683480f0849f8e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
