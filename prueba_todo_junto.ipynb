{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "nlp=spacy.load('es_core_news_sm')\n",
    "\n",
    "# Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRespuesta</th>\n",
       "      <th>Intencion</th>\n",
       "      <th>SubIntencion</th>\n",
       "      <th>Carrera</th>\n",
       "      <th>w5</th>\n",
       "      <th>Respuesta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>IA</td>\n",
       "      <td>todas</td>\n",
       "      <td>A partir de la captación y procesamiento de da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>MM</td>\n",
       "      <td>todas</td>\n",
       "      <td>Como Diseñador de Multimedios, serás un profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>DG</td>\n",
       "      <td>todas</td>\n",
       "      <td>El diseño gráfico es una disciplina indispensa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>Pub</td>\n",
       "      <td>todas</td>\n",
       "      <td>En la actualidad y desde siempre, la publicida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>RRPP</td>\n",
       "      <td>todas</td>\n",
       "      <td>Las Relaciones Públicas constituyen un conjunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>tramites</td>\n",
       "      <td>todas</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>\\nLa preinscripción puede hacerse a través de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>tramites</td>\n",
       "      <td>preinscripcion</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>\\nLa preinscripción puede hacerse a través de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>tramites</td>\n",
       "      <td>cies</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>La preinscripción puede hacerse a través de nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>tramites</td>\n",
       "      <td>requisitos</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>La preinscripción puede hacerse a través de nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>tramites</td>\n",
       "      <td>equivalencias</td>\n",
       "      <td>todas</td>\n",
       "      <td>donde</td>\n",
       "      <td>\\nLos trámites de Equivalencias se pueden inic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDRespuesta      Intencion    SubIntencion Carrera     w5  \\\n",
       "0             1  generalidades           todas      IA  todas   \n",
       "1             2  generalidades           todas      MM  todas   \n",
       "2             3  generalidades           todas      DG  todas   \n",
       "3             4  generalidades           todas     Pub  todas   \n",
       "4             5  generalidades           todas    RRPP  todas   \n",
       "..          ...            ...             ...     ...    ...   \n",
       "81           82       tramites           todas   todas  donde   \n",
       "82           83       tramites  preinscripcion   todas  donde   \n",
       "83           84       tramites            cies   todas  donde   \n",
       "84           85       tramites      requisitos   todas  donde   \n",
       "85           86       tramites   equivalencias   todas  donde   \n",
       "\n",
       "                                            Respuesta  \n",
       "0   A partir de la captación y procesamiento de da...  \n",
       "1   Como Diseñador de Multimedios, serás un profes...  \n",
       "2   El diseño gráfico es una disciplina indispensa...  \n",
       "3   En la actualidad y desde siempre, la publicida...  \n",
       "4   Las Relaciones Públicas constituyen un conjunt...  \n",
       "..                                                ...  \n",
       "81  \\nLa preinscripción puede hacerse a través de ...  \n",
       "82  \\nLa preinscripción puede hacerse a través de ...  \n",
       "83  La preinscripción puede hacerse a través de nu...  \n",
       "84  La preinscripción puede hacerse a través de nu...  \n",
       "85  \\nLos trámites de Equivalencias se pueden inic...  \n",
       "\n",
       "[86 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuestas = pd.read_csv('tbl_respuestas.csv', sep=',', encoding='utf_8')\n",
    "respuestas.drop(\"Modalidad\", axis=1, inplace=True)\n",
    "respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pedile al profe si puede pasar los enlaces de programacion logica.\n",
    "aa = input(\"texto: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quiero estudiar algo relacionado a la computacion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             oracion\n",
       "0  quiero estudiar algo relacionado a la computacion"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_textos = pd.DataFrame(columns = ['oracion'])\n",
    "df_textos.loc[0] = [aa] \n",
    "df_textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcesar(Corpus, POS=False, Lema=True, Stem=True):\n",
    "    \n",
    "    # Generar una lista de documentos de spacy para tratar el POS Tagging y la Lematización\n",
    "    docs=[]\n",
    "    for oracion in Corpus:\n",
    "        docs.append(nlp(oracion.lower())) #La lematización funciona mejor en minúsculas\n",
    "    \n",
    "    # Crear una lista de oraciones, donde cada elemento es una lista de palabras.\n",
    "    # Cada palabra está definida por una tupla (Texto, POSTag, Lema)\n",
    "    # Se omiten los tokens que son identificados como signos de puntuación\n",
    "    oraciones=[]\n",
    "    for doc in docs:\n",
    "        oracion=[]\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'PUNCT':\n",
    "                oracion.append((token.text, token.pos_, token.lemma_))\n",
    "        oraciones.append(oracion)\n",
    "    \n",
    "    fc = open('stopwords.txt', 'r', encoding='utf8')\n",
    "    stopwords = fc.read().split('\\n')\n",
    "    fc.close()\n",
    "    oraciones = [[palabra for palabra in oracion if palabra[2] not in stopwords] for oracion in oraciones]\n",
    "    \n",
    "    # Stemming\n",
    "    if Stem==True:\n",
    "        oraciones_aux=[]\n",
    "        for oracion in oraciones:\n",
    "            oracion_aux=[]\n",
    "            for palabra in oracion:\n",
    "                p_texto, p_pos, p_lema = palabra\n",
    "                # Si Lema es True, se Stemmatiza el lema; si no, se Stemmatiza la palabra original\n",
    "                if Lema==True:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_lema)))\n",
    "                else:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_texto)))\n",
    "            oraciones_aux.append(oracion_aux)\n",
    "        \n",
    "        oraciones = oraciones_aux\n",
    "    \n",
    "    # Finalmente: devolver nuevamente una lista de cadenas como la recibida, pero con el contenido\n",
    "    # de cada cadena conformado según los parámetros:\n",
    "    \n",
    "    Corpus_Procesado = [] #Variable de salida\n",
    "    \n",
    "    for doc in oraciones:\n",
    "        oracion = ''\n",
    "        for palabra in doc:\n",
    "            if Stem == True:\n",
    "                # Devolver cadena de Stemming\n",
    "                oracion = oracion + palabra[3]\n",
    "            else:\n",
    "                if Lema == True:\n",
    "                    # Devolver cadena de Lemas\n",
    "                    oracion = oracion + palabra[2]\n",
    "                else:\n",
    "                    # Devolver cadena de palabras originales\n",
    "                    oracion = oracion + palabra[0]\n",
    "            \n",
    "            if POS == True:\n",
    "                #Concatenar POS a cada palabra\n",
    "                oracion = oracion + '_' + palabra[1].lower()\n",
    "            \n",
    "            oracion = oracion + ' '\n",
    "        \n",
    "        Corpus_Procesado.append(oracion)\n",
    "        \n",
    "    return Corpus_Procesado\n",
    "\n",
    "def Corregir_Documentos(df_textos, columnas, POS=False, Lema=True, Stem=True):\n",
    "\n",
    "    for col in columnas:\n",
    "        df_textos[col] = PreProcesar(list(df_textos[col]), POS, Lema, Stem)\n",
    "    \n",
    "    # Sanear el DataFrame eliminando los duplicados y reindexándolo\n",
    "    df_textos = df_textos.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return df_textos\n",
    "\n",
    "def Generar_Matriz_BOW(df_textos, columna, binario=False, ngram=(1,2)):\n",
    "    \n",
    "    # Vectorizar, usando CountVectorizer de sklearn.feature_extraction.text\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizador = CountVectorizer(binary=binario, ngram_range=ngram)\n",
    "    X = vectorizador.fit_transform(df_textos[columna])\n",
    "    \n",
    "    # Generar el DataFrame a devolver\n",
    "    df_X = pd.DataFrame(X.toarray(), columns=vectorizador.get_feature_names())\n",
    "    df = df_textos.join(df_X)\n",
    "    \n",
    "    return vectorizador, df\n",
    "\n",
    "def Generar_Matriz_Tfidf(df_textos, columna, ngram=(1,2)):\n",
    "    \n",
    "    # Vectorizar... Directamente usar aquí el TfidfVectorizer de sklearn en vez del CountVectorizer\n",
    "    # (Lleva los mismos parámetros y directamente nos devuelve la matriz con los vectores Tf*Idf)\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizador = TfidfVectorizer(ngram_range=ngram)\n",
    "    X = vectorizador.fit_transform(df_textos[columna])\n",
    "    \n",
    "    # Generar el DataFrame a devolver\n",
    "    df_X = pd.DataFrame(X.toarray(), columns=vectorizador.get_feature_names())\n",
    "    df = df_textos.join(df_X)\n",
    "    \n",
    "    return vectorizador, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d333c3e79956f6cfdda154d497169890c9e1b3b648807dd58683480f0849f8e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
